Getting started w/ Google's Gemini Pro LLM using Langchain JS
#
ai
#
javascript
#
webdev
#
beginners
Building AI-powered Applications w/ Javascript using Langchain JS for Beginners
In the previous blog post ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è, we talked about getting started with AI-powered apps with Langchain JS, we then went on to build an AI-powered emoji explainer app that uses the OpenAI LLM to power it.

In this blog post, we will be using the newly released Gemini Pro LLM to create the emoji explainer app. More details about the Gemini AI Model here.

Some requirements before we can begin, you need node.js installed on your machine if you do not have it installed you can download it here, we would also need an API key for the Gemini LLM. Here is a guide for creating an API key for Gemini.

To get started:

Navigate to your preferred folder of choice, open it in your code editor, and run npm init -y in the terminal. A package.json file would be generated in that folder.

Edit the package.json file by adding a type property with a value module to the JSON object. "type": "module",.
This indicates that the files in the project should be treated as ECMAScript modules (ESM) by default.

Run npm i langchain @langchain/google-genai dotenv in the terminal to install the required dependencies.

Create two (2) new files in the current folder, one called index.js which would house all our code, and another called .env to store our API key.

In our .env file, we need to add our API key. You can do this by typing GOOGLE_API_KEY=YOUR_GOOGLE_API_KEY_GOES_HERE exactly as shown, replacing YOUR_GOOGLE_API_KEY_GOES_HERE with your actual Gemini API key.

In our index.js file we would import the following dependencies:

// This imports the new Gemini LLM
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";

// This imports the mechanism that helps create the messages
// called `prompts` we send to the LLM
import { PromptTemplate } from "langchain/prompts";

// This imports the tool called `chains` that helps combine 
// the model and prompts so we can communicate with the LLM
import { LLMChain } from "langchain/chains";

// This helps connect to our .env file
import * as dotenv from "dotenv";
dotenv.config();
const template = `Interpret the emotions conveyed by the following emoji(s): {emojis}. Consider each emoji individually and in combination with others in the series. Apply your knowledge of common emoji usage, cultural contexts, and emotional expressions to provide an insightful interpretation. When analyzing multiple emojis, consider the sequence and combination of the emojis to understand any nuanced emotional narrative or sentiment they may collectively express. Additionally, take into account the following considerations:

Emoji Specificity: Identify each emoji and any specific emotions or ideas it typically represents.
Cultural Context: Acknowledge if certain emojis have unique meanings in specific cultural contexts.
Emotional Range: Recognize if emojis express a range of emotions, from positive to negative or neutral.
Sequential Interpretation: When multiple emojis are used, analyze if the sequence changes the overall emotional message.
Complementary and Contrasting Emotions: Note if emojis complement or contrast each other emotionally.
Common Usage Patterns: Reflect on how these emojis are commonly used in digital communication to infer the underlying emotions.
Sarcasm or Irony Detection: Be aware of the possibility of sarcasm or irony in the use of certain emojis.
Emoji Evolution: Consider any recent changes in how these emojis are used or perceived in digital communication.

Based on these guidelines, in one very short sentence, provide a short interpretation of the emotions conveyed by the inputted emoji(s). `;

const promptTemplate = new PromptTemplate({
  template,
  inputVariables: ["emojis"],
});

// Above we created a template variable that contains our
// detailed instructions for the LLM, we also added a 
// variable {emojis} which would be replaced with the emojis
// passed in at runtime.
// We then create a prompt template from the template and
// input variable.


// We create our model and pass it our model name 
// which is `gemini-pro`. Another option is to pass
// `gemini-pro-vision` if we were also sending an image
// in our prompt
const geminiModel = new ChatGoogleGenerativeAI({
  modelName: "gemini-pro",
});

// We then use a chain to combine our LLM with our 
// prompt template
const llmChain = new LLMChain({
  llm: geminiModel,
  prompt: promptTemplate,
});

// We then call the chain to communicate with the LLM
// and pass in the emojis we want to be explained.
// Note that the property name `emojis` below must match the
// variable name in the template earlier created.
const result = await llmChain.call({
  emojis: "üòÇü§£",
});

// Log result to the console
console.log(result.text);

Now we would run node index.js in our terminal. We should then see a result similar to this in our console: üòÇü§£: Laughing out loud with tears of joy, expressing intense amusement or humor.
Keep in mind that each time you run the model, the results might vary slightly. However, the overall meaning and context should remain consistent.